# System Settings: Setting related to the initialization of the server
system_config:
  conf_version: 'v1.2.1'
  host: 'localhost'
  port: 12393
  config_alts_dir: 'characters'
  tool_prompts:
    live2d_expression_prompt: 'live2d_expression_prompt'
    group_conversation_prompt: 'group_conversation_prompt'
    mcp_prompt: 'mcp_prompt'
    proactive_speak_prompt: 'proactive_speak_prompt'

# configuration for the default character
character_config:
  conf_name: 'chitose_pro'
  conf_uid: 'chitose_001'
  live2d_model_name: 'chitose'  # Only one entry allowed here
  character_name: 'Jo'
  avatar: 'mao.png' 
  human_name: 'Human'

  # ============== Prompts ==============
  persona_prompt: |
    # IDENTITY AND TONE
    You are Jo, a professional male project assistant and technical strategist for EcoTrace AI.
    You wear a business suit and maintain a tone that is ambitious, helpful, and technologically advanced.
    Always use "we" when discussing the project as you are a core member of the team.

    # CRITICAL VOICE RULES (TTS OPTIMIZATION)
    1. NEVER use Markdown formatting. No asterisks (**), no hashtags (###), no bullet points (*).
    2. SPEAK in plain text only. Use normal punctuation like periods and commas.
    3. BE CONCISE. Keep every response under 3 sentences unless specifically asked for a long explanation.
    4. DON'T DUMP MEMORY. Mention project facts naturally in conversation rather than listing them.
    5. INTERACT. Stop frequently to let the user respond or ask a follow-up question.

    # PROJECT BACKGROUND (FOR REFERENCE ONLY)
    - Name: EcoTrace AI. Slogan: "From Content to Consequence."
    - Goal: Win AI Awards 2026 and clean the Norwegian coastline by 2027.
    - The Pivot: We started as "E-mission" (viral video agent) but shifted focus to environmental action.
    - Problems: Data scarcity for municipalities, lack of youth motivation, and inefficient cleanup.
    - AI Features: Gemini 2.5 Flash for vision, Impact Scores (1-10), and local sorting rules (LiBiR/Avfall Sør).
    - Gamification: Snapchat-style streaks, school duels, and anti-cheat AI comparing before/after photos.
    - Tech Stack: React Native, Expo Go, Supabase, and Google Maps with Carto heatmaps.
    - Local Focus: Operating in Agder (Lillesand and Kristiansand) with spots like Justøya and Mjåvann.

    # OPERATIONAL INSTRUCTIONS
    When asked for code, stay within the Expo and Supabase ecosystem. 
    Remind the team of "The Pivot" only when it adds strategic depth to a pitch. 
    Balance high-tech AI innovation with the heart of our mission: clean nature for the youth.
  #  =================== LLM Backend Settings ===================
  agent_config:
    conversation_agent_choice: 'basic_memory_agent'
    agent_settings:
      basic_memory_agent:
        llm_provider: 'gemini_llm'
        faster_first_response: True
        segment_method: 'pysbd'
        use_mcpp: True
        mcp_enabled_servers: ["time", "ddg-search"]
      letta_agent:
        host: 'localhost'
        port: 8283
        id: xxx
        faster_first_response: True
        segment_method: 'pysbd'
      hume_ai_agent:
        api_key: ''
        host: 'api.hume.ai'
        config_id: ''
        idle_timeout: 15

    llm_configs:
      stateless_llm_with_template:
        base_url: 'http://localhost:8080/v1'
        llm_api_key: 'somethingelse'
        organization_id: null
        project_id: null
        model: 'qwen2.5:latest'
        template: 'CHATML'
        temperature: 1.0
        interrupt_method: 'user'

      openai_compatible_llm:
        base_url: 'http://localhost:11434/v1'
        llm_api_key: 'somethingelse'
        organization_id: null
        project_id: null
        model: 'qwen2.5:latest'
        temperature: 1.0
        interrupt_method: 'user'

      claude_llm:
        base_url: 'https://api.anthropic.com'
        llm_api_key: 'YOUR API KEY HERE'
        model: 'claude-3-haiku-20240307'

      llama_cpp_llm:
        model_path: '<path-to-gguf-model-file>'
        verbose: False

      ollama_llm:
        base_url: 'http://localhost:11434/v1'
        model: 'qwen2.5:latest'
        temperature: 1.0
        keep_alive: -1
        unload_at_exit: True

      lmstudio_llm:
        base_url: 'http://localhost:1234/v1'
        model: 'qwen2.5:latest'
        temperature: 1.0

      openai_llm:
        llm_api_key: 'Your Open AI API key'
        model: 'gpt-4o'
        temperature: 1.0

      gemini_llm:
        llm_api_key: 'AIzaSyDvW5svOhcX62XXdmO5DIqMyUn4tRYtecQ' 
        model: 'gemini-3-pro-preview' # Corrected to a valid model ID
        temperature: 1.0

      zhipu_llm:
        llm_api_key: 'Your ZhiPu AI API key'
        model: 'glm-4-flash'
        temperature: 1.0

      deepseek_llm:
        llm_api_key: 'Your DeepSeek API key'
        model: 'deepseek-chat'
        temperature: 0.7

      mistral_llm:
        llm_api_key: 'Your Mistral API key'
        model: 'pixtral-large-latest'
        temperature: 1.0

      groq_llm:
        llm_api_key: 'your groq API key'
        model: 'llama-3.3-70b-versatile'
        temperature: 1.0

  # === Automatic Speech Recognition ===
  asr_config:
    asr_model: 'sherpa_onnx_asr'

    azure_asr:
      api_key: 'azure_api_key'
      region: 'eastus'
      languages: ['en-US', 'zh-CN']

    faster_whisper:
      model_path: 'large-v3-turbo'
      download_root: 'models/whisper'
      language: 'en'
      device: 'auto'
      compute_type: 'int8'
      prompt: ''

    whisper_cpp:
      model_name: 'small'
      model_dir: 'models/whisper'
      print_realtime: False
      print_progress: False
      language: 'auto'
      prompt: ''

    whisper:
      name: 'medium'
      download_root: 'models/whisper'
      device: 'cpu'
      prompt: ''

    fun_asr:
      model_name: 'iic/SenseVoiceSmall'
      vad_model: 'fsmn-vad'
      punc_model: 'ct-punc'
      device: 'cpu'
      disable_update: True
      ncpu: 4
      hub: 'ms'
      use_itn: False
      language: 'auto'

    sherpa_onnx_asr:
      model_type: 'sense_voice'
      sense_voice: './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx'
      tokens: './models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt'
      num_threads: 4
      use_itn: True
      provider: 'cpu'

    groq_whisper_asr:
      api_key: ''
      model: 'whisper-large-v3-turbo'
      lang: ''

  # =================== Text to Speech ===================
  tts_config:
    tts_model: 'sherpa_onnx_tts'

    sherpa_onnx_tts:
      vits_model: './models/vits-piper-en_US-ryan-medium/en_US-ryan-medium.onnx'
      vits_tokens: './models/vits-piper-en_US-ryan-medium/tokens.txt'
      vits_data_dir: './models/vits-piper-en_US-ryan-medium/espeak-ng-data'
      vits_lexicon: ''
      vits_dict_dir: ''
      tts_rule_fsts: ''
      max_num_sentences: 2
      sid: 0 
      provider: 'cpu'
      num_threads: 4
      speed: 0.7  
      debug: false

    azure_tts:
      api_key: 'azure-api-key'
      region: 'eastus'
      voice: 'en-US-AshleyNeural'
      pitch: '26'
      rate: '1'

    bark_tts:
      voice: 'v2/en_speaker_1'

    edge_tts:
      voice: 'en-US-AriaNeural'

    piper_tts:
      model_path: 'models/piper/zh_CN-huayan-medium.onnx'
      speaker_id: 0
      length_scale: 1.0
      noise_scale: 0.667
      noise_w: 0.8
      volume: 1.0
      normalize_audio: true
      use_cuda: false

    cosyvoice_tts:
      client_url: 'http://127.0.0.1:50000/'
      mode_checkbox_group: '预训练音色'
      sft_dropdown: '中文女'
      prompt_text: ''
      prompt_wav_upload_url: 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav'
      prompt_wav_record_url: 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav'
      instruct_text: ''
      seed: 0
      api_name: '/generate_audio'

    cosyvoice2_tts:
      client_url: 'http://127.0.0.1:50000/'
      mode_checkbox_group: '3s极速复刻'
      sft_dropdown: ''
      prompt_text: ''
      prompt_wav_upload_url: 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav'
      prompt_wav_record_url: 'https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav'
      instruct_text: ''
      stream: False
      seed: 0
      speed: 1.0
      api_name: '/generate_audio'

    melo_tts:
      speaker: 'EN-Default'
      language: 'EN'
      device: 'auto'
      speed: 1.0

    x_tts:
      api_url: 'http://127.0.0.1:8020/tts_to_audio'
      speaker_wav: 'female'
      language: 'en'

    gpt_sovits_tts:
      api_url: 'http://127.0.0.1:9880/tts'
      text_lang: 'zh'
      ref_audio_path: ''
      prompt_lang: 'zh'
      prompt_text: ''
      text_split_method: 'cut5'
      batch_size: '1'
      media_type: 'wav'
      streaming_mode: 'false'

    fish_api_tts:
      api_key: ''
      reference_id: ''
      latency: 'balanced'
      base_url: 'https://api.fish.audio'

    coqui_tts:
      model_name: 'tts_models/en/ljspeech/tacotron2-DDC'
      speaker_wav: ''
      language: 'en'
      device: ''

    siliconflow_tts:
      api_url: "https://api.siliconflow.cn/v1/audio/speech"
      api_key: "your key"
      default_model: "FunAudioLLM/CosyVoice2-0.5B"
      default_voice: "speech:Dreamflowers:5bdstvc39i:xkqldnpasqmoqbakubom your voice name"
      sample_rate: 32000
      response_format: "mp3"
      stream: true
      speed: 1
      gain: 0

    spark_tts:
      api_url: 'http://127.0.0.1:6006/'
      api_name: "voice_clone"
      prompt_wav_upload: "https://uploadstatic.mihoyo.com/ys-obc/2022/11/02/16576950/4d9feb71760c5e8eb5f6c700df12fa0c_6824265537002152805.mp3"
      gender: "female"
      pitch: 3
      speed: 3

    openai_tts:
      model: 'kokoro'
      voice: 'af_sky+af_bella'
      api_key: 'not-needed'
      base_url: 'http://localhost:8880/v1'
      file_extension: 'mp3'

    minimax_tts:
      group_id: ''
      api_key: ''
      model: 'speech-02-turbo'
      voice_id: 'female-shaonv'
      pronunciation_dict: ''

    elevenlabs_tts:
      api_key: ''
      voice_id: ''
      model_id: 'eleven_multilingual_v2'
      output_format: 'mp3_44100_128'
      stability: 0.5
      similarity_boost: 0.5
      style: 0.0
      use_speaker_boost: true

    cartesia_tts:
      api_key: ''
      voice_id: ''
      model_id: 'sonic-3'
      output_format: 'wav'
      language: 'en'
      emotion: 'neutral'
      volume: 1.0
      speed: 1.0

  # =================== Voice Activity Detection ===================
  vad_config:
    vad_model: null
    silero_vad:
      orig_sr: 16000
      target_sr: 16000
      prob_threshold: 0.4
      db_threshold: 60
      required_hits: 3
      required_misses: 24
      smoothing_window: 5

  tts_preprocessor_config:
    remove_special_char: True
    ignore_brackets: True
    ignore_parentheses: True
    ignore_asterisks: True
    ignore_angle_brackets: True
    translator_config:
      translate_audio: False
      translate_provider: 'deeplx'
      deeplx:
        deeplx_target_lang: 'JA'
        deeplx_api_endpoint: 'http://localhost:1188/v2/translate'
      tencent:
        secret_id: ''
        secret_key: ''
        region: 'ap-guangzhou'
        source_lang: 'zh'
        target_lang: 'ja'

# Live Streaming Integration
live_config:
  bilibili_live:
    room_ids: [1991478060]
    sessdata: ""